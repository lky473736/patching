{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:49.396834Z",
     "start_time": "2025-05-05T17:45:49.392638Z"
    },
    "id": "dJGCTJBmXNMJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.254375Z",
     "start_time": "2025-05-05T17:45:49.399583Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZhjXdu6RE6g",
    "outputId": "379a9958-e854-4d08-b6be-137e84364748"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  activity_labels = pd.read_csv(os.path.join(data_path, 'activity_labels.txt'),\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:43: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
      "/var/folders/_z/gryfr07n59jgb3wrd062h1ym0000gn/T/ipykernel_3616/3340623117.py:49: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded inertial signals data with shape: (7352, 128, 9) (train), (2947, 128, 9) (test)\n",
      "/content/activity_labels.txt\n",
      "Training data shape: (7352, 128, 9)\n",
      "Training labels shape: (7352, 6)\n",
      "Test data shape: (2947, 128, 9)\n",
      "Test labels shape: (2947, 6)\n",
      "\n",
      "Activity labels:\n",
      "   class_index          class_name\n",
      "0            1             WALKING\n",
      "1            2    WALKING_UPSTAIRS\n",
      "2            3  WALKING_DOWNSTAIRS\n",
      "3            4             SITTING\n",
      "4            5            STANDING\n",
      "5            6              LAYING\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_uci_har_data(data_path):\n",
    "    # Load activity labels\n",
    "    activity_labels = pd.read_csv(os.path.join(data_path, 'activity_labels.txt'),\n",
    "                                 delim_whitespace=True, header=None,\n",
    "                                 names=['class_index', 'class_name'])\n",
    "\n",
    "    # Load labels\n",
    "    y_train = pd.read_csv(os.path.join(data_path, 'y_train.txt'), header=None)\n",
    "    y_test = pd.read_csv(os.path.join(data_path, 'y_test.txt'), header=None)\n",
    "\n",
    "    # Convert labels to numpy arrays\n",
    "    y_train = y_train.values.flatten().astype('int32') - 1  # Make labels zero-indexed\n",
    "    y_test = y_test.values.flatten().astype('int32') - 1  # Make labels zero-indexed\n",
    "\n",
    "    # Load inertial signals data\n",
    "    train_signals_paths = [\n",
    "        os.path.join(data_path, 'body_acc_x_train.txt'),\n",
    "        os.path.join(data_path, 'body_acc_y_train.txt'),\n",
    "        os.path.join(data_path, 'body_acc_z_train.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_x_train.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_y_train.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_z_train.txt'),\n",
    "        os.path.join(data_path, 'total_acc_x_train.txt'),\n",
    "        os.path.join(data_path, 'total_acc_y_train.txt'),\n",
    "        os.path.join(data_path, 'total_acc_z_train.txt')\n",
    "    ]\n",
    "\n",
    "    test_signals_paths = [\n",
    "        os.path.join(data_path, 'body_acc_x_test.txt'),\n",
    "        os.path.join(data_path, 'body_acc_y_test.txt'),\n",
    "        os.path.join(data_path, 'body_acc_z_test.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_x_test.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_y_test.txt'),\n",
    "        os.path.join(data_path, 'body_gyro_z_test.txt'),\n",
    "        os.path.join(data_path, 'total_acc_x_test.txt'),\n",
    "        os.path.join(data_path, 'total_acc_y_test.txt'),\n",
    "        os.path.join(data_path, 'total_acc_z_test.txt')\n",
    "    ]\n",
    "\n",
    "    # Load and stack training data\n",
    "    x_train_signals = []\n",
    "    for path in train_signals_paths:\n",
    "        signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
    "        x_train_signals.append(signal)\n",
    "\n",
    "    # Load and stack test data\n",
    "    x_test_signals = []\n",
    "    for path in test_signals_paths:\n",
    "        signal = pd.read_csv(path, delim_whitespace=True, header=None).values\n",
    "        x_test_signals.append(signal)\n",
    "\n",
    "    # Convert to numpy arrays with shape (n_samples, n_timestamps, n_features)\n",
    "    # Each signal has shape (n_samples, n_timestamps)\n",
    "    # We'll transpose to get shape (n_samples, n_timestamps, n_features)\n",
    "    x_train = np.transpose(np.array(x_train_signals), (1, 2, 0)).astype('float32')\n",
    "    x_test = np.transpose(np.array(x_test_signals), (1, 2, 0)).astype('float32')\n",
    "\n",
    "    print(f\"Loaded inertial signals data with shape: {x_train.shape} (train), {x_test.shape} (test)\")\n",
    "\n",
    "    # Normalize each feature independently\n",
    "    n_samples_train, n_timestamps, n_features = x_train.shape\n",
    "    n_samples_test = x_test.shape[0]\n",
    "\n",
    "    # Reshape to normalize features independently\n",
    "    x_train_reshaped = x_train.reshape((n_samples_train * n_timestamps, n_features))\n",
    "    x_test_reshaped = x_test.reshape((n_samples_test * n_timestamps, n_features))\n",
    "\n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    x_train_reshaped = scaler.fit_transform(x_train_reshaped)\n",
    "    x_test_reshaped = scaler.transform(x_test_reshaped)\n",
    "\n",
    "    # Reshape back to original shape\n",
    "    x_train = x_train_reshaped.reshape((n_samples_train, n_timestamps, n_features))\n",
    "    x_test = x_test_reshaped.reshape((n_samples_test, n_timestamps, n_features))\n",
    "\n",
    "    # One-hot encode labels\n",
    "    y_train_onehot = tf.keras.utils.to_categorical(y_train, num_classes=6)\n",
    "    y_test_onehot = tf.keras.utils.to_categorical(y_test, num_classes=6)\n",
    "\n",
    "    return x_train, y_train, y_train_onehot, x_test, y_test, y_test_onehot, activity_labels\n",
    "\n",
    "data_path = \"../UCI_HAR_Dataset/for_colab/\"\n",
    "x_train, y_train, y_train_onehot, x_test, y_test, y_test_onehot, activity_labels = load_uci_har_data(data_path)\n",
    "\n",
    "print (\"/content/activity_labels.txt\")\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train_onehot.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test_onehot.shape}\")\n",
    "print(\"\\nActivity labels:\")\n",
    "print(activity_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.269640Z",
     "start_time": "2025-05-05T17:45:52.257024Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwgD-AZRRE80",
    "outputId": "9ff1b4e2-7bf5-416b-9292-41c9c854c8a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: (7352, 128, 9)\n",
      "Original test data shape: (2947, 128, 9)\n",
      "Final training data shape: (7352, 128, 9)\n",
      "Final training labels shape: (7352, 6)\n",
      "Final test data shape: (2947, 128, 9)\n",
      "Final test labels shape: (2947, 6)\n"
     ]
    }
   ],
   "source": [
    "def split_sequences(data, window_size=128, step=64):\n",
    "    \"\"\"\n",
    "    Split the data into sequences with overlapping windows\n",
    "\n",
    "    Args:\n",
    "        data: Input data with shape (n_samples, n_features)\n",
    "        window_size: Number of time steps in each sequence\n",
    "        step: Step size between consecutive sequences\n",
    "\n",
    "    Returns:\n",
    "        Sequences with shape (n_sequences, window_size, n_features)\n",
    "    \"\"\"\n",
    "    n_samples, n_features = data.shape\n",
    "    sequences = []\n",
    "\n",
    "    for i in range(0, n_samples - window_size + 1, step):\n",
    "        sequence = data[i:i + window_size]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "    return np.array(sequences)\n",
    "\n",
    "# -----\n",
    "# Since the inertial signals data is already in the format of (samples, timestamps, features),\n",
    "# we don't need to use the split_sequences function for basic formatting, but we'll still use it\n",
    "# if needed for resizing or overlap\n",
    "\n",
    "# Check the current shape of the data\n",
    "print(f\"Original training data shape: {x_train.shape}\")\n",
    "print(f\"Original test data shape: {x_test.shape}\")\n",
    "\n",
    "# The data already has 128 timestamps per sample, so we can use it directly\n",
    "# If we need to adjust window size or create overlapping windows:\n",
    "window_size = 128  # This is already the size in the dataset\n",
    "step = 128  # Non-overlapping by default - set to smaller value for overlap\n",
    "\n",
    "# Check if we need to reshape the data\n",
    "if x_train.shape[1] != window_size or step != window_size:\n",
    "    print(\"Reshaping data to adjust window size or create overlapping samples...\")\n",
    "    # Flatten the data to 2D and then recreate sequences\n",
    "    x_train_flat = x_train.reshape(x_train.shape[0] * x_train.shape[1], x_train.shape[2])\n",
    "    x_test_flat = x_test.reshape(x_test.shape[0] * x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "    # Create new sequences\n",
    "    x_train_seq = split_sequences(x_train_flat, window_size=window_size, step=step)\n",
    "    x_test_seq = split_sequences(x_test_flat, window_size=window_size, step=step)\n",
    "\n",
    "    # Create corresponding labels for sequences\n",
    "    # For each sequence, we'll use the mode of the labels\n",
    "    orig_samples_per_window = x_train.shape[1] / window_size\n",
    "\n",
    "    y_train_seq = []\n",
    "    for i in range(0, len(x_train_flat) - window_size + 1, step):\n",
    "        # Map back to original sample indices\n",
    "        orig_sample_idx = int(i / x_train.shape[1])\n",
    "        mode_label = y_train[orig_sample_idx]\n",
    "        y_train_seq.append(mode_label)\n",
    "\n",
    "    y_test_seq = []\n",
    "    for i in range(0, len(x_test_flat) - window_size + 1, step):\n",
    "        # Map back to original sample indices\n",
    "        orig_sample_idx = int(i / x_test.shape[1])\n",
    "        mode_label = y_test[orig_sample_idx]\n",
    "        y_test_seq.append(mode_label)\n",
    "\n",
    "    y_train_seq = np.array(y_train_seq)\n",
    "    y_test_seq = np.array(y_test_seq)\n",
    "else:\n",
    "    # If no reshaping is needed, use the data directly\n",
    "    x_train_seq = x_train\n",
    "    x_test_seq = x_test\n",
    "    y_train_seq = y_train\n",
    "    y_test_seq = y_test\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_seq_onehot = tf.keras.utils.to_categorical(y_train_seq, num_classes=6)\n",
    "y_test_seq_onehot = tf.keras.utils.to_categorical(y_test_seq, num_classes=6)\n",
    "\n",
    "print(f\"Final training data shape: {x_train_seq.shape}\")\n",
    "print(f\"Final training labels shape: {y_train_seq_onehot.shape}\")\n",
    "print(f\"Final test data shape: {x_test_seq.shape}\")\n",
    "print(f\"Final test labels shape: {y_test_seq_onehot.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.290490Z",
     "start_time": "2025-05-05T17:45:52.272888Z"
    },
    "id": "QoL9uvj-R3An"
   },
   "outputs": [],
   "source": [
    "X_train_seq = x_train_seq.copy()\n",
    "X_test_seq = x_test_seq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.809762Z",
     "start_time": "2025-05-05T17:45:52.293211Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-hxi_kubamDj",
    "outputId": "924db53f-ba3d-4122-f008-5c8a1d6c25f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,170</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,674</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">59,178</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,256</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ abfa (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ABFA</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">34,560</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mst__block          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">35,328</span> │ abfa[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MST_Block</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,968</span> │ mst__block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ mst__block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ mst__block[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">390</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m9\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m640\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │      \u001b[38;5;34m8,320\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │     \u001b[38;5;34m16,170\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │     \u001b[38;5;34m37,674\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │     \u001b[38;5;34m59,178\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │        \u001b[38;5;34m168\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │        \u001b[38;5;34m168\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │        \u001b[38;5;34m168\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m126\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m16,256\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m512\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ abfa (\u001b[38;5;33mABFA\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m34,560\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mst__block          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m35,328\u001b[0m │ abfa[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mMST_Block\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m131,968\u001b[0m │ mst__block[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ mst__block[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ mst__block[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m16,512\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m16,512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │        \u001b[38;5;34m390\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">400,572</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m400,572\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,424</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m399,424\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,148</span> (4.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,148\u001b[0m (4.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers # Import optimizers here\n",
    "\n",
    "# -------------------------\n",
    "# ABFA 모듈 정의\n",
    "# -------------------------\n",
    "class ABFA(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, activity_classes=6, dropout_rate=0.2, **kwargs):\n",
    "        super(ABFA, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.activity_classes = activity_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.action_prototypes = self.add_weight(\n",
    "            name='action_prototypes',\n",
    "            shape=(self.activity_classes, input_shape[-1]),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.embedding_proj = layers.Dense(input_shape[-1])\n",
    "        self.augment_proj = layers.Dense(input_shape[-1])\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.dropout = layers.Dropout(self.dropout_rate)\n",
    "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_proj = self.embedding_proj(inputs)\n",
    "        proto_similarity = tf.einsum('btd,cd->btc', x_proj, self.action_prototypes)\n",
    "        proto_attention = tf.nn.softmax(proto_similarity, axis=-1)\n",
    "        enhanced = tf.einsum('btc,cd->btd', proto_attention, self.action_prototypes)\n",
    "        augmented = self.augment_proj(enhanced)\n",
    "        x = self.bn(inputs + augmented)\n",
    "        x = self.dropout(x)\n",
    "        return self.layer_norm(x)\n",
    "\n",
    "# -------------------------\n",
    "# MST Block 정의\n",
    "# -------------------------\n",
    "class MST_Block(layers.Layer):\n",
    "    def __init__(self, filters, kernel_sizes=(3, 5, 7), **kwargs):\n",
    "        super(MST_Block, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "\n",
    "        if len(kernel_sizes) == 3:\n",
    "            self.filter_dims = [filters // 4, filters // 4, filters // 2]\n",
    "        else:\n",
    "            self.filter_dims = [filters // 2, filters // 2]\n",
    "\n",
    "        self.conv_layers = []\n",
    "        for i, k_size in enumerate(kernel_sizes):\n",
    "            self.conv_layers.append(\n",
    "                layers.DepthwiseConv1D(\n",
    "                    kernel_size=k_size,\n",
    "                    strides=1,\n",
    "                    padding='same',\n",
    "                    depth_multiplier=1\n",
    "                )\n",
    "            )\n",
    "        self.proj_layers = [\n",
    "            layers.Conv1D(self.filter_dims[i], kernel_size=1, padding='same') for i in range(len(kernel_sizes))\n",
    "        ]\n",
    "        self.output_proj = layers.Conv1D(filters, kernel_size=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = []\n",
    "        for conv, proj in zip(self.conv_layers, self.proj_layers):\n",
    "            x = conv(inputs)\n",
    "            x = proj(x)\n",
    "            outputs.append(x)\n",
    "        x = layers.Concatenate()(outputs)\n",
    "        return self.output_proj(x)\n",
    "\n",
    "# -------------------------\n",
    "# 모델 정의\n",
    "# -------------------------\n",
    "def build_model3(input_shape, num_classes=6):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial projection\n",
    "    x = layers.Conv1D(64, kernel_size=1, activation=None)(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Conv1D(128, kernel_size=1, activation=None)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Multi-Scale CNN Path\n",
    "    kernel_sizes = [3, 7, 11]\n",
    "    multi_scale_outputs = []\n",
    "    for k in kernel_sizes:\n",
    "        branch = layers.Conv1D(\n",
    "            filters=128 // len(kernel_sizes),\n",
    "            kernel_size=k,\n",
    "            padding='same',\n",
    "            activation='relu'\n",
    "        )(x)\n",
    "        branch = layers.BatchNormalization()(branch)\n",
    "        multi_scale_outputs.append(branch)\n",
    "\n",
    "    x = layers.Concatenate()(multi_scale_outputs)\n",
    "    x = layers.Conv1D(128, kernel_size=1)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # ABFA block\n",
    "    x = ABFA(filters=128, activity_classes=num_classes)(x)\n",
    "\n",
    "    # MST block\n",
    "    x = MST_Block(filters=128, kernel_sizes=(3, 5, 7))(x)\n",
    "\n",
    "    # Transformer Encoder block (1 layer)\n",
    "    attn_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "    x = layers.Add()([x, attn_output])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    ffn_output = layers.Dense(128, activation='relu')(x)\n",
    "    ffn_output = layers.Dense(128)(ffn_output)\n",
    "    x = layers.Add()([x, ffn_output])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    # GlobalAveragePooling + Classifier\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model3 = build_model3(input_shape=(window_size, X_train_seq.shape[2]))\n",
    "model3.summary()\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.824223Z",
     "start_time": "2025-05-05T17:45:52.811712Z"
    },
    "id": "GAikxo-9a1nZ"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "# from sklearn.model_selection import train_test_split # Import train_test_split\n",
    "\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_seq, y_train_seq_onehot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# early_stopping = callbacks.EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=10,\n",
    "#     restore_best_weights=True\n",
    "# )\n",
    "\n",
    "# reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.5,\n",
    "#     patience=5,\n",
    "#     min_lr=1e-5\n",
    "# )\n",
    "\n",
    "# history = model3.fit(\n",
    "#     X_train_split,\n",
    "#     y_train_split,\n",
    "#     epochs=100,\n",
    "#     batch_size=32,\n",
    "#     validation_data=(X_val_split, y_val_split),\n",
    "#     callbacks=[early_stopping, reduce_lr],\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.832029Z",
     "start_time": "2025-05-05T17:45:52.827975Z"
    },
    "id": "W_PC6FrBEWoN"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.title('Model Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history.history['loss'], label='Train Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Model Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.841265Z",
     "start_time": "2025-05-05T17:45:52.835486Z"
    },
    "id": "6i2d4TxCEWr2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "\n",
    "# # Assuming your activity labels are in a CSV file, load them\n",
    "# # Replace 'activity_labels.csv' with the actual file path\n",
    "# try:\n",
    "#     activity_labels = pd.read_csv('activity_labels.csv')\n",
    "# except FileNotFoundError:\n",
    "#     # If the file doesn't exist, create a DataFrame manually\n",
    "#     activity_labels = pd.DataFrame({\n",
    "#         'class_name': ['WALKING', 'WALKING_UPSTAIRS', 'WALKING_DOWNSTAIRS', 'SITTING', 'STANDING', 'LAYING'],\n",
    "#         'label': [0, 1, 2, 3, 4, 5]  # Assuming labels are 0-indexed\n",
    "#     })\n",
    "\n",
    "# y_pred_probs = model3.predict(X_test_seq)  # Get predicted probabilities\n",
    "# y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
    "# y_true = np.argmax(y_test_seq_onehot, axis=1)  # Get true labels from one-hot encoded data\n",
    "\n",
    "\n",
    "# precision = precision_score(y_true, y_pred, average='weighted')\n",
    "# recall = recall_score(y_true, y_pred, average='weighted')\n",
    "# f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "# # Calculate specificity for each class\n",
    "# def specificity_score(y_true, y_pred, num_classes=6):\n",
    "#     specificities = []\n",
    "\n",
    "#     for i in range(num_classes):\n",
    "#         true_negative = np.sum((y_true != i) & (y_pred != i))\n",
    "#         false_positive = np.sum((y_true != i) & (y_pred == i))\n",
    "\n",
    "#         if true_negative  false_positive == 0:\n",
    "#             specificities.append(1.0)\n",
    "#         else:\n",
    "#             specificities.append(true_negative / (true_negative + false_positive))\n",
    "\n",
    "#     return specificities\n",
    "\n",
    "# specificities = specificity_score(y_true, y_pred)\n",
    "# avg_specificity = np.mean(specificities)\n",
    "\n",
    "# test_loss, test_acc = model3.evaluate(X_test_seq, y_test_seq_onehot, verbose=0)\n",
    "\n",
    "# print(\"\\nEvaluation Metrics:\")\n",
    "# print(f\"Accuracy: {test_acc:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall: {recall:.4f}\")\n",
    "# print(f\"F1 Score: {f1:.4f}\")\n",
    "# print(f\"Average Specificity: {avg_specificity:.4f}\")\n",
    "\n",
    "# print(\"\\nClass-wise Specificities:\")\n",
    "# for i, spec in enumerate(specificities):\n",
    "#     print(f\"Class {i} ({activity_labels.iloc[i, 0]}): {spec:.4f}\") # Assuming 'class_name' is in the first column (index 0)\n",
    "\n",
    "# cm = confusion_matrix(y_true, y_pred)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "#            xticklabels=activity_labels['class_name'].values,\n",
    "#            yticklabels=activity_labels['class_name'].values)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix - PatchFormer (UCI-HAR)')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:45:52.850499Z",
     "start_time": "2025-05-05T17:45:52.843624Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "eUXX_E3rEWwG",
    "outputId": "86e82666-66a0-4f18-93c6-644b96a2b46a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nInput (batch_size, time_steps, channels)\\n    ↓\\n[Initial Projection]\\n    Conv1D(kernel=1, filters=64) → BatchNorm → ReLU\\n    ↓\\n    Conv1D(kernel=1, filters=128) → BatchNorm → ReLU\\n    ↓\\n[Multi-Scale CNN Path]\\n    ┌─ Conv1D(kernel=3,  filters=128/3≈42) → BatchNorm\\n    ├─ Conv1D(kernel=7,  filters=128/3≈42) → BatchNorm\\n    └─ Conv1D(kernel=11, filters=128/3≈42) → BatchNorm\\n        ↓\\n    Concatenate(branches) → Conv1D(kernel=1, filters=128) → BatchNorm → ReLU\\n    ↓\\n[ABFA Block]\\n    • 입력 차원: (time_steps, 128)\\n    • action_prototypes: (num_classes, 128)\\n    • 내부:\\n        – Dense→프로젝트 → proto 유사도 계산 → softmax attention\\n        – attention ⊗ prototypes → augment_proj → residual + BN → Dropout → LayerNorm\\n    ↓\\n[MST_Block]\\n    • DepthwiseConv1D(kernel=3) → Conv1D(filters=32)\\n    • DepthwiseConv1D(kernel=5) → Conv1D(filters=32)\\n    • DepthwiseConv1D(kernel=7) → Conv1D(filters=64)\\n        ↓\\n    Concatenate → Conv1D(kernel=1, filters=128)\\n    ↓\\n[Transformer Encoder Block]\\n    MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\\n      → Add(x) → LayerNormalization\\n    ↓\\n    Feed-Forward: Dense(128, ReLU) → Dense(128)\\n      → Add(x) → LayerNormalization\\n    ↓\\nGlobalAveragePooling1D\\n    ↓\\nDense(128, ReLU) → Dropout(0.2) → Dense(64, ReLU)\\n    ↓\\nDense(num_classes, Softmax)\\n초기 투영(Initial Projection): 1×1 컨볼루션으로 채널 차원 확장\\n\\n다중 스케일 CNN(Multi-Scale CNN Path): 서로 다른 커널 크기로 병렬 특징 추출 후 통합\\n\\nABFA Block: 학습된 행동 프로토타입과의 attention 기반 특징 증강\\n\\nMST_Block: 깊이별(depthwise) 컨볼루션으로 다중 스케일 시간 특징 캡처\\n\\nTransformer Encoder: 자기-어텐션과 FFN으로 시퀀스 전역 관계 학습\\n\\n분류기(Classifier): 전역 풀링 후 완전 연결 계층으로 최종 클래스 예측\\n\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Input (batch_size, time_steps, channels)\n",
    "    ↓\n",
    "[Initial Projection]\n",
    "    Conv1D(kernel=1, filters=64) → BatchNorm → ReLU\n",
    "    ↓\n",
    "    Conv1D(kernel=1, filters=128) → BatchNorm → ReLU\n",
    "    ↓\n",
    "[Multi-Scale CNN Path]\n",
    "    ┌─ Conv1D(kernel=3,  filters=128/3≈42) → BatchNorm\n",
    "    ├─ Conv1D(kernel=7,  filters=128/3≈42) → BatchNorm\n",
    "    └─ Conv1D(kernel=11, filters=128/3≈42) → BatchNorm\n",
    "        ↓\n",
    "    Concatenate(branches) → Conv1D(kernel=1, filters=128) → BatchNorm → ReLU\n",
    "    ↓\n",
    "[ABFA Block]\n",
    "    • 입력 차원: (time_steps, 128)\n",
    "    • action_prototypes: (num_classes, 128)\n",
    "    • 내부:\n",
    "        – Dense→프로젝트 → proto 유사도 계산 → softmax attention\n",
    "        – attention ⊗ prototypes → augment_proj → residual + BN → Dropout → LayerNorm\n",
    "    ↓\n",
    "[MST_Block]\n",
    "    • DepthwiseConv1D(kernel=3) → Conv1D(filters=32)\n",
    "    • DepthwiseConv1D(kernel=5) → Conv1D(filters=32)\n",
    "    • DepthwiseConv1D(kernel=7) → Conv1D(filters=64)\n",
    "        ↓\n",
    "    Concatenate → Conv1D(kernel=1, filters=128)\n",
    "    ↓\n",
    "[Transformer Encoder Block]\n",
    "    MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
    "      → Add(x) → LayerNormalization\n",
    "    ↓\n",
    "    Feed-Forward: Dense(128, ReLU) → Dense(128)\n",
    "      → Add(x) → LayerNormalization\n",
    "    ↓\n",
    "GlobalAveragePooling1D\n",
    "    ↓\n",
    "Dense(128, ReLU) → Dropout(0.2) → Dense(64, ReLU)\n",
    "    ↓\n",
    "Dense(num_classes, Softmax)\n",
    "초기 투영(Initial Projection): 1×1 컨볼루션으로 채널 차원 확장\n",
    "\n",
    "다중 스케일 CNN(Multi-Scale CNN Path): 서로 다른 커널 크기로 병렬 특징 추출 후 통합\n",
    "\n",
    "ABFA Block: 학습된 행동 프로토타입과의 attention 기반 특징 증강\n",
    "\n",
    "MST_Block: 깊이별(depthwise) 컨볼루션으로 다중 스케일 시간 특징 캡처\n",
    "\n",
    "Transformer Encoder: 자기-어텐션과 FFN으로 시퀀스 전역 관계 학습\n",
    "\n",
    "분류기(Classifier): 전역 풀링 후 완전 연결 계층으로 최종 클래스 예측\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F04ZssXeQdhR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Eg2XdWqQeJn"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:46:08.182213Z",
     "start_time": "2025-05-05T17:46:08.089693Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xdKhmYgyQejO",
    "outputId": "78b099ad-4890-4c6b-c808-dcd6a006ba6d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model3.save(\"./ABFA_MST.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CaUI8AI_SiHn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
